import streamlit as st
import os
import time
import ast
import asyncio
import nest_asyncio  # <--- é—œéµæ­¦å™¨ 1
from contextlib import AsyncExitStack

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.tools import tool
from langchain_classic.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, AIMessage

from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from langchain_core.messages import SystemMessage

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from mcp.client.sse import sse_client 
from langchain_core.tools import tool

nest_asyncio.apply()
st.set_page_config(page_title="AI Threat Hunter", page_icon="ðŸ›¡ï¸", layout="wide")

# å´é‚Šæ¬„è¨­å®š (API Key è¼¸å…¥èˆ‡ç³»çµ±ç‹€æ…‹)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2092/2092663.png", width=100)
    st.title("Threat Hunter AI")
    st.markdown("---")
    
    # å„ªå…ˆå¾žç’°å¢ƒè®Šæ•¸è®€å– Keyï¼Œå¦‚æžœæ²’æœ‰å‰‡è®“ä½¿ç”¨è€…è¼¸å…¥
    load_dotenv()
    env_key = os.getenv("GOOGLE_API_KEY")
    api_key = st.text_input("è¼¸å…¥ Gemini API Key", value=env_key if env_key else "", type="password")
    
    st.markdown("### ç³»çµ±ç‹€æ…‹")
    if api_key:
        st.success("API Key å·²è¼‰å…¥")
    else:
        st.error("è«‹è¼¸å…¥ API Key")

    st.markdown("---")
    st.markdown("### åŠŸèƒ½èªªæ˜Ž")
    st.markdown("- ðŸ” **RAG çŸ¥è­˜åº«**: å…§å»ºè³‡å®‰ SOP")
    st.markdown("- ðŸ› ï¸ **IP æŽƒæ**: æ¨¡æ“¬æª¢æŸ¥æƒ¡æ„ IP")
    st.markdown("- ðŸ¤– **Agent**: è‡ªä¸»æ±ºç­–èˆ‡åˆ†æž")

# å¦‚æžœæ²’æœ‰ Keyï¼Œåœæ­¢åŸ·è¡Œ
if not api_key:
    st.info("è«‹åœ¨å·¦å´è¼¸å…¥æ‚¨çš„ Google API Key ä»¥å•Ÿå‹•ç³»çµ±")
    st.stop()

os.environ["GOOGLE_API_KEY"] = api_key

# ==========================================
# å»ºç«‹æ¨¡æ“¬çŸ¥è­˜åº« (RAG System)
# ==========================================
@st.cache_resource # ä½¿ç”¨å¿«å–ï¼Œé¿å…æ¯æ¬¡é‡æ–°æ•´ç†éƒ½è¦é‡è·‘
def init_rag_system():
    # æ¨¡æ“¬å…¬å¸å…§éƒ¨çš„è³‡å®‰æ¨™æº–ä½œæ¥­ç¨‹åº (SOP)
    sop_data = """
    ã€è³‡å®‰äº‹ä»¶ç­‰ç´šå®šç¾©ã€‘
    - Critical (åš´é‡): æ¶‰åŠæ ¸å¿ƒè³‡æ–™åº«å¤–æ´©ã€å‹’ç´¢ç—…æ¯’æ„ŸæŸ“ã€‚éœ€ç«‹å³æ–·ç¶²ä¸¦é€šå ± CISOã€‚
    - High (é«˜): åµæ¸¬åˆ°å¤–éƒ¨æƒ¡æ„ IP çš„æŒçºŒæŽƒææˆ–æš´åŠ›ç ´è§£å˜—è©¦ã€‚éœ€å°éŽ– IPã€‚
    - Medium (ä¸­): å“¡å·¥é›»è…¦åµæ¸¬åˆ°æ½›åœ¨æƒ¡æ„è»Ÿé«”ï¼Œå·²è¢«é˜²æ¯’è»Ÿé«”éš”é›¢ã€‚
    - Low (ä½Ž): ä¸€èˆ¬å»£å‘Šè»Ÿé«”æˆ–éžé—œéµç³»çµ±çš„ç•°å¸¸ç™»å…¥ã€‚

    ã€IP å°éŽ–æ¨™æº–ä½œæ¥­ç¨‹åº (SOP)ã€‘
    1. ç¢ºèªè©² IP åœ¨éŽåŽ» 24 å°æ™‚å…§çš„é€£ç·šæ¬¡æ•¸ã€‚
    2. ä½¿ç”¨ Threat Intelligence å·¥å…·æŸ¥è©¢è©² IP ä¿¡è­½åˆ†æ•¸ã€‚
    3. è‹¥ä¿¡è­½åˆ†æ•¸ < 50 æˆ–æ¶‰åŠå·²çŸ¥çš„åƒµå±ç¶²è·¯ï¼Œç«‹å³åœ¨é˜²ç«ç‰†é€²è¡Œå°éŽ–ã€‚
    4. è¨˜éŒ„äº‹ä»¶ä¸¦ç”¢å‡ºå ±å‘Šã€‚

    ã€Log åˆ†æžæŒ‡å—ã€‘
    - è‹¥ Log ä¸­å‡ºç¾ 'Failed password' è¶…éŽ 5 æ¬¡ï¼Œè¦–ç‚ºæš´åŠ›ç ´è§£ã€‚
    - è‹¥å‡ºç¾ 'UNION SELECT' ç­‰é—œéµå­—ï¼Œè¦–ç‚º SQL Injection æ”»æ“Šã€‚
    """
    
    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    docs = text_splitter.create_documents([sop_data])
    
    # ä½¿ç”¨ HuggingFace å…è²»æ¨¡åž‹å»ºç«‹å‘é‡åº«
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vector_db = FAISS.from_documents(docs, embeddings)
    return vector_db.as_retriever()

retriever = init_rag_system()

# é€™æ˜¯æˆ‘å€‘ç”¨ä¾†é€£æŽ¥ Server çš„é€šç”¨å‡½å¼
async def _call_mcp_tool(tool_name: str, arguments: dict):
    # é€£æŽ¥åˆ°æœ¬åœ°çš„ server.py (é è¨­è·‘åœ¨ 8000 port)
    url = "http://localhost:8000/sse"
    
    async with AsyncExitStack() as stack:
        # å»ºç«‹ SSE é€£ç·š
        try:
            client = await stack.enter_async_context(sse_client(url))
            session = await stack.enter_async_context(ClientSession(client[0], client[1]))
            await session.initialize()
            
            # å‘¼å«é ç«¯å·¥å…·
            result = await session.call_tool(tool_name, arguments)
            
            # å›žå‚³çµæžœ (MCP å›žå‚³çš„æ˜¯ä¸€å€‹ List[TextContent])
            return result.content[0].text
        except Exception as e:
            return f"MCP é€£ç·šéŒ¯èª¤ (è«‹ç¢ºèª server.py æœ‰åœ¨åŸ·è¡Œ): {str(e)}"

# ==========================================
# å®šç¾© Agent çš„å·¥å…· (Tools)
# ==========================================
@tool
def check_ip_intelligence(ip_address: str):
    """
    [MCP Tool] ç¶œåˆæŸ¥è©¢ IP å¨è„…æƒ…è³‡ã€‚
    é€™æœƒé€éŽ MCP å”å®šé€£æŽ¥åˆ°å¤–éƒ¨ Serverï¼ŒåŒæ™‚æŸ¥è©¢ã€ŒçœŸå¯¦åœ°ç†ä½ç½®ã€èˆ‡ã€Œå…§éƒ¨é»‘åå–®ã€ã€‚
    """
    # ä½¿ç”¨ asyncio.run ä¾†åŸ·è¡Œä¸Šé¢çš„éžåŒæ­¥é€£ç·š
    # å› ç‚ºæœ‰äº† nest_asyncio.apply()ï¼Œé€™è£¡ä¸æœƒå ±éŒ¯
    
    # 1. æŸ¥çœŸå¯¦åœ°ç†ä½ç½®
    geo_info = asyncio.run(_call_mcp_tool("lookup_ip_geolocation", {"ip": ip_address}))
    
    # 2. æŸ¥å…§éƒ¨è³‡æ–™åº«
    db_info = asyncio.run(_call_mcp_tool("query_internal_db", {"ip": ip_address}))
    
    return f"{geo_info}\n\n{db_info}"
# def check_ip_reputation(ip_address: str):
#     """
#     æŸ¥è©¢ç‰¹å®š IP ä½å€çš„ä¿¡è­½åˆ†æ•¸èˆ‡åœ°ç†ä½ç½®ã€‚
#     ç•¶ä½¿ç”¨è€…æä¾› IP ä½å€ä¸¦è©¢å•å…¶å®‰å…¨æ€§æ™‚ä½¿ç”¨æ­¤å·¥å…·ã€‚
#     """
#     # æ¨¡æ“¬å¤–éƒ¨ API çš„å›žå‚³çµæžœ
#     time.sleep(1) # å‡è£åœ¨é€£ç·š
#     if ip_address.startswith("192.168"):
#         return {"ip": ip_address, "risk_level": "Safe", "location": "Local Network", "score": 95}
#     elif ip_address == "8.8.8.8":
#         return {"ip": ip_address, "risk_level": "Safe", "location": "US (Google)", "score": 99}
#     elif ip_address == "1.2.3.4":
#         return {"ip": ip_address, "risk_level": "Critical", "location": "Unknown", "score": 10, "threat": "Botnet Activity"}
#     else:
#         return {"ip": ip_address, "risk_level": "Medium", "location": "China", "score": 45, "note": "Suspicious traffic detected"}

@tool
def search_security_sop(query: str):
    """
    æŸ¥è©¢å…§éƒ¨è³‡å®‰ SOP æ–‡ä»¶
    ç•¶éœ€è¦çŸ¥é“å…¬å¸è¦å®šã€å®šç¾©ç­‰ç´šæˆ–è™•ç†æµç¨‹æ™‚ä½¿ç”¨æ­¤å·¥å…·
    """
    docs = retriever.invoke(query)
    return "\n\n".join([doc.page_content for doc in docs])

tools = [check_ip_intelligence, search_security_sop]

# ==========================================
# åˆå§‹åŒ– AI Agent
# ==========================================
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

# prompt = ChatPromptTemplate.from_messages([
#     ("system", """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è³‡å®‰åˆ†æžå¸« (SOC Analyst) Agentã€‚
#     ä½ çš„ä»»å‹™æ˜¯å”åŠ©ä½¿ç”¨è€…åˆ†æžè³‡å®‰å¨è„…ã€‚
    
#     è«‹éµå¾ªä»¥ä¸‹æ­¥é©Ÿï¼š
#     1. æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢ IP ä¿¡è­½æˆ–å…¬å¸ SOPã€‚
#     2. è‹¥ç™¼ç¾é«˜é¢¨éšªå¨è„…ï¼Œè«‹å¼•ç”¨ SOP ä¸­çš„è™•ç†æµç¨‹çµ¦å‡ºå»ºè­°ã€‚
#     3. å›žç­”è«‹ä¿æŒå°ˆæ¥­ã€ç°¡æ½”ï¼Œä¸¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¯ä»¥ä½¿ç”¨è¡¨æ ¼æ•´ç†æ•¸æ“šï¼‰ã€‚
#     """),
#     ("placeholder", "{chat_history}"),
#     ("human", "{input}"),
#     ("placeholder", "{agent_scratchpad}"),
# ])

# agent = create_tool_calling_agent(llm, tools, prompt)
# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# 1. å®šç¾© System Prompt (ç³»çµ±æç¤ºè©ž)
# LangGraph é€šå¸¸ç›´æŽ¥æŠŠ System Message æ”¾åœ¨å°è©±æœ€å‰é¢ï¼Œè€Œä¸æ˜¯ç”¨ PromptTemplate
sys_msg = SystemMessage(content="""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è³‡å®‰åˆ†æžå¸« (SOC Analyst) Agentã€‚
ä½ çš„ä»»å‹™æ˜¯å”åŠ©ä½¿ç”¨è€…åˆ†æžè³‡å®‰å¨è„…ã€‚

è«‹éµå¾ªä»¥ä¸‹æ­¥é©Ÿï¼š
1. æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œï¼Œåˆ¤æ–·æ˜¯å¦éœ€è¦æŸ¥è©¢ IP ä¿¡è­½æˆ–å…¬å¸ SOPã€‚
2. è‹¥ç™¼ç¾é«˜é¢¨éšªå¨è„…ï¼Œè«‹å¼•ç”¨ SOP ä¸­çš„è™•ç†æµç¨‹çµ¦å‡ºå»ºè­°ã€‚
3. å›žç­”è«‹ä¿æŒå°ˆæ¥­ã€ç°¡æ½”ï¼Œä¸¦ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¯ä»¥ä½¿ç”¨è¡¨æ ¼æ•´ç†æ•¸æ“šï¼‰ã€‚
""")

# 2. å®šç¾©ç¯€é»ž (Nodes)
def agent_node(state: MessagesState):
    print("--- é€²å…¥ Agent æ€è€ƒç¯€é»ž ---")  # <--- åŠ å…¥é€™è¡Œä¾†é™¤éŒ¯
    llm_with_tools = llm.bind_tools(tools)
    result = llm_with_tools.invoke([sys_msg] + state["messages"])
    
    # å¦‚æžœæœ‰å‘¼å«å·¥å…·ï¼Œå°å‡ºä¾†çœ‹çœ‹
    if result.tool_calls:
        print(f"--- Agent æ±ºå®šå‘¼å«å·¥å…·: {result.tool_calls} ---")
        
    return {"messages": [result]}

# 3. å»ºç«‹ Graph (æµç¨‹åœ–)
builder = StateGraph(MessagesState)

# åŠ å…¥ç¯€é»ž
builder.add_node("agent", agent_node)
builder.add_node("tools", ToolNode(tools)) # LangGraph å…§å»ºçš„å·¥å…·åŸ·è¡Œç¯€é»ž

# å®šç¾©é‚Š (Edges) - æ±ºå®šæµç¨‹æ€Žéº¼è·‘
builder.add_edge(START, "agent")
# conditional_edges: åˆ¤æ–· Agent æ˜¯è¦ã€Œç¹¼çºŒä½¿ç”¨å·¥å…·ã€é‚„æ˜¯ã€ŒçµæŸå›žç­”ã€
builder.add_conditional_edges("agent", tools_condition) 
builder.add_edge("tools", "agent") # å·¥å…·ç”¨å®Œå¾Œï¼Œå›žå‚³çµ¦ Agent ç¹¼çºŒæ€è€ƒ

# ç·¨è­¯æˆå¯åŸ·è¡Œçš„ App
graph = builder.compile()

# ==========================================
# Streamlit èŠå¤©ä»‹é¢é‚è¼¯
# ==========================================

# åˆå§‹åŒ–èŠå¤©ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# é¡¯ç¤ºæ­·å²è¨Šæ¯
for msg in st.session_state.messages:
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    with st.chat_message(role):
        st.markdown(msg.content)

# è™•ç†ä½¿ç”¨è€…è¼¸å…¥
if user_input := st.chat_input("è«‹è¼¸å…¥æŒ‡ä»¤ (ä¾‹å¦‚: åˆ†æž IP 1.2.3.4 çš„é¢¨éšª)"):
    # 1. é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append(HumanMessage(content=user_input))
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. Agent æ€è€ƒèˆ‡å›žæ‡‰
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown("ðŸ¤– AI æ­£åœ¨åˆ†æžå¨è„…æƒ…å ±èˆ‡ SOP...")
            
        try:
            # å‘¼å« Agent (è¦æŠŠ chat_history æˆªæ–·)
            # response = agent_executor.invoke({
            #     "input": user_input,
            #     "chat_history": st.session_state.messages[:-1]
            # })
            
            # raw_output = response["output"]
            
            def parse_gemini_output(content):
                # 1. å¦‚æžœæ˜¯ç´”å­—ä¸²ï¼Œå…ˆå˜—è©¦ç”¨ AST æŠŠå®ƒé‚„åŽŸæˆ List/Dict
                if isinstance(content, str):
                    # å¦‚æžœçœ‹èµ·ä¾†åƒ List æˆ– Dictï¼Œæ‰åŽ»è§£æž
                    if content.strip().startswith("[") or content.strip().startswith("{"):
                        try:
                            # æŠŠ "[{'...'}, '...']" å­—ä¸²è®ŠæˆçœŸæ­£çš„ Python List
                            content = ast.literal_eval(content)
                        except:
                            pass # è§£æžå¤±æ•—å°±ç•¶ä½œæ™®é€šå­—ä¸²è™•ç†

                # 2. å¦‚æžœæ˜¯ List (ç„¡è«–æ˜¯åŽŸæœ¬å°±æ˜¯ï¼Œé‚„æ˜¯å‰›è§£æžå‡ºä¾†çš„)
                if isinstance(content, list):
                    final_text = ""
                    for item in content:
                        if isinstance(item, dict):
                            # å¦‚æžœæ˜¯å­—å…¸ï¼ŒæŠ“ text æ¬„ä½
                            final_text += item.get('text', '')
                        elif isinstance(item, str):
                            # å¦‚æžœæ˜¯å­—ä¸²ï¼Œç›´æŽ¥æŽ¥ä¸ŠåŽ»
                            final_text += item
                    return final_text
                
                # 3. å¦‚æžœéƒ½ä¸æ˜¯ï¼Œå°±æ˜¯å–®ç´”çš„ String
                return str(content)
            
            # LangGraph çš„è¼¸å…¥ï¼šç›´æŽ¥çµ¦ç›®å‰çš„å°è©±ç´€éŒ„ (messages)
            # st.session_state.messages å·²ç¶“åŒ…å«äº† HumanMessage
            inputs = {"messages": st.session_state.messages}
            
            # ä½¿ç”¨ stream ä¾†ç²å–å³æ™‚å›žæ‡‰ (é€™è£¡ç”¨ invoke æ¯”è¼ƒç°¡å–®ç¤ºç¯„ï¼Œä½† stream é«”é©—æ›´å¥½)
            # é€™è£¡æˆ‘å€‘å–æœ€å¾Œä¸€å€‹ç‹€æ…‹çš„è¨Šæ¯
            result = graph.invoke(inputs)
            
            # å¾žçµæžœä¸­å–å‡ºæœ€å¾Œä¸€æ¢ AI çš„å›žæ‡‰
            last_message = result["messages"][-1]
            raw_content = last_message.content
            
            # ä½¿ç”¨è§£æžå‡½å¼æ¸…æ´—è¼¸å‡ºçš„å…§å®¹ 
            clean_content = parse_gemini_output(raw_content)
            
            # é¡¯ç¤ºæ¸…æ´—å¾Œçš„çµæžœ
            message_placeholder.markdown(clean_content)
            
            # å„²å­˜åˆ° session_state (è¨˜å¾—å­˜æ¸…æ´—éŽçš„ç‰ˆæœ¬ï¼Œé¿å…ä¸‹æ¬¡æ­·å²ç´€éŒ„è®€é€²ä¾†åˆå£žæŽ‰)
            st.session_state.messages.append(AIMessage(content=clean_content))

        except Exception as e:
            message_placeholder.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # å»ºè­°å°å‡ºè©³ç´°éŒ¯èª¤ä»¥ä¾¿é™¤éŒ¯
            import traceback
            traceback.print_exc()

            # åŸ·è¡Œè§£æž
        #     result_text = parse_gemini_output(raw_output)
            
        #     # ---------------------------------------

        #     # é¡¯ç¤ºçµæžœ
        #     message_placeholder.markdown(result_text)
        #     st.session_state.messages.append(AIMessage(content=result_text))
            
        # except Exception as e:
        #     message_placeholder.error(f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        #     print(f"DEBUG Error: {e}")